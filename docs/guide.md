# üöÄ Retail Video Analytics Pipeline - H∆∞·ªõng D·∫´n End-to-End

> **Streaming Lakehouse Architecture**: Vision AI ‚Üí Pulsar ‚Üí Flink ‚Üí Iceberg ‚Üí Trino

H∆∞·ªõng d·∫´n chi ti·∫øt t·ª´ng b∆∞·ªõc ƒë·ªÉ kh·ªüi ch·∫°y pipeline ph√¢n t√≠ch video b√°n l·∫ª theo ki·∫øn tr√∫c Medallion (Bronze-Silver-Gold).

---

## üìã M·ª•c L·ª•c

1. [Chu·∫©n b·ªã M√¥i tr∆∞·ªùng Python](#1-chu·∫©n-b·ªã-m√¥i-tr∆∞·ªùng-python)
2. [Kh·ªüi ch·∫°y H·∫° t·∫ßng](#2-kh·ªüi-ch·∫°y-h·∫°-t·∫ßng)
3. [T·∫°o D·ªØ li·ªáu t·ª´ Video](#3-t·∫°o-d·ªØ-li·ªáu-t·ª´-video)
4. [Submit Bronze Job](#4-submit-bronze-job)
5. [Ingestion v√†o Pulsar](#5-ingestion-v√†o-pulsar)
6. [Submit Silver & Gold Jobs](#6-submit-silver--gold-jobs)
7. [Truy v·∫•n Lakehouse](#7-truy-v·∫•n-lakehouse)
8. [Monitoring & Troubleshooting](#8-monitoring--troubleshooting)

> ‚ö†Ô∏è **L∆∞u √Ω quan tr·ªçng v·ªÅ th·ª© t·ª±:**
> 1. Submit **Bronze Job** (Section 4) tr∆∞·ªõc khi replay data
> 2. Replay data v√†o Pulsar (Section 5)
> 3. Submit **Silver & Gold Jobs** (Section 6) sau khi ƒë√£ c√≥ data trong Bronze

---

## 1. Chu·∫©n b·ªã M√¥i tr∆∞·ªùng Python

### 1.1. T·∫°o Virtual Environment

M·ªü terminal (Git Bash/PowerShell) t·∫°i th∆∞ m·ª•c g·ªëc:

```bash
# T·∫°o m√¥i tr∆∞·ªùng ·∫£o (ch·ªâ ch·∫°y 1 l·∫ßn)
python -m venv venv

# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
# Windows (Git Bash/PowerShell):
source venv/Scripts/activate

# Windows (Command Prompt):
venv\Scripts\activate
```

### 1.2. C√†i ƒë·∫∑t Dependencies

```bash
pip install -r setup.txt
```

**C√°c th∆∞ vi·ªán ch√≠nh:**
- `ultralytics` - YOLO11 object detection
- `opencv-python` - Video processing
- `pulsar-client` - Apache Pulsar client
- `deep-sort-realtime` - Object tracking

---

## 2. Kh·ªüi ch·∫°y H·∫° t·∫ßng

### 2.1. Kh·ªüi ƒë·ªông Docker Compose

```bash
docker-compose up -d --build
```

‚è±Ô∏è **Ch·ªù 1-2 ph√∫t** ƒë·ªÉ c√°c service kh·ªüi ƒë·ªông ho√†n to√†n.

### 2.2. Ki·ªÉm tra Services

```bash
# Ki·ªÉm tra containers ƒëang ch·∫°y
docker ps

# Ki·ªÉm tra logs n·∫øu c√≥ v·∫•n ƒë·ªÅ
docker-compose logs -f [service_name]
```

**Services & Ports:**
- **Pulsar Broker**: `6650` (client), `8084` (admin)
- **Flink JobManager**: `8081` (Web UI)
- **MinIO**: `9001` (Console)
- **Trino**: `8082` (Query Engine)
- **Iceberg REST**: `8181` (Catalog)

---

## 3. T·∫°o D·ªØ li·ªáu t·ª´ Video

### 3.1. Ch·∫°y Vision Module

```bash
# ƒê·∫£m b·∫£o venv ƒë√£ k√≠ch ho·∫°t
python vision/main.py
```

**üìä Output:**
- File JSONL: `data/metadata/video.jsonl`
- Real-time video window v·ªõi bounding boxes

**‚å®Ô∏è Controls:**
- `q` - D·ª´ng processing
- `ESC` - Tho√°t

**C·∫•u tr√∫c Output JSON:**
```json
{
  "source": {
    "store_id": "store_01",
    "camera_id": "cam_01",
    "stream_id": "stream_001"
  },
  "detections": [
    {
      "det_id": "d_1732276800_001",
      "class": "person",
      "bbox": {"x1": 100, "y1": 200, "x2": 300, "y2": 400},
      "conf": 0.92,
      "track_id": 5
    }
  ],
  "frame_index": 1234,
  "capture_ts": "2025-11-22T10:30:00.123Z",
  "image_size": {"width": 1280, "height": 720}
}
```

---

## 4. Submit Bronze Job

> ‚ö†Ô∏è **QUAN TR·ªåNG:** Submit Bronze Job **TR∆Ø·ªöC** khi g·ª≠i data v√†o Pulsar ƒë·ªÉ ƒë·∫£m b·∫£o consumer s·∫µn s√†ng nh·∫≠n messages.

### 4.1. Submit Bronze Job (Streaming)

```bash
docker exec flink-jobmanager sh -c \
  "./bin/flink run -d -c org.rva.BronzeIngestJob /opt/flink/usrlib/bronze-job.jar"
```

**Job Details:**
- **Class:** `org.rva.BronzeIngestJob`
- **Mode:** Detached (`-d`) - ch·∫°y background
- **Source:** Pulsar topic `persistent://retail/metadata/events`
- **Sink:** Iceberg table `lakehouse.rva.bronze_raw`
- **Checkpoint:** Every 60 seconds

### 4.2. Ki·ªÉm tra Job Status

```bash
# Xem danh s√°ch jobs ƒëang ch·∫°y
docker exec flink-jobmanager sh -c "./bin/flink list"

# Ho·∫∑c truy c·∫≠p Flink Web UI: http://localhost:8081
```

‚úÖ **X√°c nh·∫≠n:** ƒê·∫£m b·∫£o Bronze Job ƒëang ·ªü tr·∫°ng th√°i `RUNNING` tr∆∞·ªõc khi ti·∫øp t·ª•c Section 5.

---

## 5. Ingestion v√†o Pulsar

> üí° **L∆∞u √Ω:** Ch·ªâ ch·∫°y b∆∞·ªõc n√†y **SAU KHI** Flink Bronze Job ƒë√£ `RUNNING`.

### 5.1. Replay Messages t·ª´ JSONL

```bash
# K√≠ch ho·∫°t venv (n·∫øu ch∆∞a)
source venv/Scripts/activate

# Ch·∫°y script replay (30 FPS simulation)
python scripts/replay_jsonl_to_pulsar.py
```

**C·∫•u h√¨nh m·∫∑c ƒë·ªãnh:**
- Topic: `persistent://retail/metadata/events`
- Service URL: `pulsar://localhost:6650`
- FPS: 30 (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh trong script)

### 5.2. Verify D·ªØ li·ªáu trong Pulsar

#### Ki·ªÉm tra Topic Stats

```bash
docker exec pulsar-broker bin/pulsar-admin topics stats \
  persistent://retail/metadata/events
```

**C√°c metrics quan tr·ªçng:**
- `msgInCounter` - T·ªïng messages ƒë√£ nh·∫≠n
- `msgOutCounter` - Messages ƒë√£ consume
- `msgBacklog` - Messages ch∆∞a x·ª≠ l√Ω (n√™n = 0 n·∫øu Flink ƒëang consume)
- `storageSize` - Dung l∆∞·ª£ng topic

#### Xem Subscriptions

```bash
docker exec pulsar-broker bin/pulsar-admin topics subscriptions \
  persistent://retail/metadata/events
```

#### Xem Metadata

```bash
docker exec pulsar-broker bin/pulsar-admin topics stats-internal \
  persistent://retail/metadata/events
```

### 5.3. Test v·ªõi Sample Data (Optional)

```bash
# G·ª≠i 5 test messages v√†o Pulsar
docker exec pulsar-broker sh -c "python3 -c \"
import pulsar, json, time
client = pulsar.Client('pulsar://localhost:6650')
producer = client.create_producer('persistent://retail/metadata/events')
msg = {
  'source': {'store_id': 'S001', 'camera_id': 'CAM01', 'stream_id': 'stream1'},
  'detections': [{'det_id': 'd1', 'class': 'person', 'bbox': {'x1': 100, 'y1': 200}}],
  'image_size': {'width': 1280, 'height': 720}
}
for i in range(5):
    producer.send(json.dumps(msg).encode('utf-8'))
    print(f'Sent message {i+1}')
    time.sleep(0.5)
producer.close()
client.close()
print('Done')
\""
```

---

## 6. Submit Silver & Gold Jobs

> üí° **L∆∞u √Ω:** Ch·∫°y sau khi ƒë√£ replay data v√† ch·ªù Bronze checkpoint (~60s) ƒë·ªÉ c√≥ data trong `bronze_raw`.

### 6.1. Verify Bronze Data

```bash
# Ch·ªù checkpoint
sleep 65

# Ki·ªÉm tra data ƒë√£ c√≥ trong Bronze
docker exec trino sh -c "trino --catalog lakehouse --schema rva --execute \
  'SELECT COUNT(*) FROM bronze_raw'"
```

### 6.2. Submit Silver Job (Streaming)

```bash
docker exec flink-jobmanager sh -c \
  "./bin/flink run -d -c org.rva.silver.SilverJob /opt/flink/usrlib/silver-job.jar"
```



**Job Details:**
- **Source:** Iceberg table `lakehouse.rva.bronze_raw`
- **Sink:** Iceberg table `lakehouse.rva.silver_detection`

### 6.3. Submit Gold Batch Job

```bash
# Ch·ªù Silver checkpoint tr∆∞·ªõc
sleep 65

docker exec flink-jobmanager sh -c \
  "./bin/flink run -d -c org.rva.gold.GoldBatchJob /opt/flink/usrlib/gold-job.jar"

# ch·∫°y streaming

docker exec flink-jobmanager sh -c \
  "./bin/flink run -d -c org.rva.gold.GoldStreamingJob /opt/flink/usrlib/gold-job.jar"

```

**Job Details:**
- **Source:** Iceberg table `lakehouse.rva.silver_detection`
- **Sink:** C√°c tables: `gold_people_per_minute`, `gold_track_summary`, `gold_zone_dwell`, `gold_zone_heatmap`

### 6.4. Ki·ªÉm tra All Jobs

```bash
docker exec flink-jobmanager sh -c "./bin/flink list"
```

‚úÖ **X√°c nh·∫≠n:** C·∫£ 3 jobs (Bronze, Silver, Gold) ƒë·ªÅu ·ªü tr·∫°ng th√°i `RUNNING`.

---

## 7. Truy v·∫•n Lakehouse

### 7.1. Ki·ªÉm tra MinIO (Storage)

```bash
# Setup MinIO client alias
docker exec minio mc alias set local \
  http://localhost:9000 minioadmin minioadmin123

# Xem c·∫•u tr√∫c th∆∞ m·ª•c
docker exec minio mc ls -r local/warehouse/rva/bronze_raw/

# Ki·ªÉm tra data files
docker exec minio mc ls -r local/warehouse/rva/bronze_raw/data/

# Ki·ªÉm tra metadata files
docker exec minio mc ls -r local/warehouse/rva/bronze_raw/metadata/
```

### 7.2. Query v·ªõi Trino

‚è±Ô∏è **L∆∞u √Ω:** Ch·ªù ~60 gi√¢y sau khi submit job ƒë·ªÉ Flink checkpoint commit data.

```bash
# Ch·ªù checkpoint
sleep 65

# Query aggregate
docker exec trino sh -c "trino --catalog lakehouse --schema rva --execute \
  'SELECT store_id, camera_id, COUNT(*) as cnt 
   FROM bronze_raw 
   GROUP BY store_id, camera_id'"

# Query chi ti·∫øt
docker exec trino sh -c "trino --catalog lakehouse --schema rva --execute \
  'SELECT * FROM bronze_raw LIMIT 10'"

# Ki·ªÉm tra schema
docker exec trino sh -c "trino --catalog lakehouse --schema rva --execute \
  'DESCRIBE bronze_raw'"
```

### 7.3. Truy c·∫≠p Trino Console

M·ªü browser: **http://localhost:8082**

```sql
-- Query m·∫´u
SELECT 
  store_id,
  camera_id,
  DATE_FORMAT(ingest_ts, '%Y-%m-%d %H:%i') as hour,
  COUNT(*) as message_count
FROM lakehouse.rva.bronze_raw
GROUP BY 
  store_id, 
  camera_id, 
  DATE_FORMAT(ingest_ts, '%Y-%m-%d %H:%i')
ORDER BY hour DESC
LIMIT 20;
```

---

## 8. Monitoring & Troubleshooting

### 8.0. Grafana Dashboards

**Grafana UI:** http://localhost:3000 (user/pass m·∫∑c ƒë·ªãnh `admin` / `admin` n·∫øu ch∆∞a ƒë·ªïi)

Datasource `Trino Lakehouse` ƒë√£ ƒë∆∞·ª£c provision s·∫µn (tr·ªè t·ªõi Trino catalog `iceberg`, schema `rva`).  
C√°c dashboard ch√≠nh:

- **RVA - People Overview**: ƒë·ªçc t·ª´ `gold_people_per_minute`, cho b·∫£ng detections/unique_people theo ph√∫t v√† camera.
- **RVA - Zone Dwell & Heatmap**: ƒë·ªçc t·ª´ `gold_zone_dwell`, cho visits v√† dwell time theo zone_x/zone_y.
- **RVA - Track Summary**: ƒë·ªçc t·ª´ `gold_track_summary`, cho danh s√°ch track v·ªõi duration, movement (delta_x/delta_y) v√† avg_conf.

Ch·ªâ c·∫ßn ƒë·∫£m b·∫£o Bronze/Silver/Gold jobs ƒë√£ ch·∫°y xong, sau ƒë√≥ m·ªü Grafana v√† ch·ªçn c√°c dashboard n√†y ƒë·ªÉ xem s·ªë li·ªáu.

### 8.1. Flink Monitoring

**Flink Web UI:** http://localhost:8081

**Metrics quan tr·ªçng:**
- `numRecordsIn` - Records ƒë·ªçc t·ª´ Pulsar
- `numRecordsOut` - Records ghi v√†o Iceberg
- `checkpointDuration` - Th·ªùi gian checkpoint
- `lastCheckpointSize` - K√≠ch th∆∞·ªõc checkpoint

**CLI Commands:**
```bash
# Xem job details
docker exec flink-jobmanager sh -c "./bin/flink list -r"

# Cancel job (thay JOB_ID)
docker exec flink-jobmanager sh -c "./bin/flink cancel <JOB_ID>"

# Xem logs
docker logs flink-taskmanager -f
```

### 8.2. Pulsar Monitoring

```bash
# Ki·ªÉm tra broker health
curl http://localhost:8084/admin/v2/brokers/health

# Xem cluster info
docker exec pulsar-broker bin/pulsar-admin clusters list

# Xem namespace policies
docker exec pulsar-broker bin/pulsar-admin namespaces policies retail/metadata
```

### 8.3. Common Issues

#### Issue 1: Job kh√¥ng consume messages

**Ki·ªÉm tra:**
```bash
# Verify subscription t·ªìn t·∫°i
docker exec pulsar-broker bin/pulsar-admin topics subscriptions \
  persistent://retail/metadata/events

# Xem subscription stats
docker exec pulsar-broker bin/pulsar-admin topics stats \
  persistent://retail/metadata/events | grep -A 20 "subscriptions"
```

#### Issue 2: Data kh√¥ng xu·∫•t hi·ªán trong Trino

**Nguy√™n nh√¢n:** Ch∆∞a c√≥ checkpoint commit.

**Gi·∫£i ph√°p:** Ch·ªù 60+ gi√¢y ho·∫∑c force checkpoint:
```bash
docker exec flink-jobmanager sh -c \
  "./bin/flink savepoint <JOB_ID>"
```

#### Issue 3: S3/MinIO connection error

**Ki·ªÉm tra:**
```bash
# Test MinIO connectivity
docker exec flink-jobmanager curl -I http://minio:9000/minio/health/live

# Verify S3 plugin
docker exec flink-jobmanager ls -la /opt/flink/plugins/s3-fs-hadoop/
```

### 8.4. Cleanup & Reset

```bash
# Stop t·∫•t c·∫£ services
docker-compose down

# X√≥a volumes (‚ö†Ô∏è m·∫•t d·ªØ li·ªáu)
docker-compose down -v

# X√≥a old jobs
docker exec flink-jobmanager sh -c "./bin/flink cancel <JOB_ID>"

# Reset Pulsar topic
docker exec pulsar-broker bin/pulsar-admin topics delete \
  persistent://retail/metadata/events
```

---

## üìö Tham Kh·∫£o

- **Flink Documentation:** https://flink.apache.org/
- **Pulsar Documentation:** https://pulsar.apache.org/
- **Iceberg Documentation:** https://iceberg.apache.org/
- **Trino Documentation:** https://trino.io/docs/

---

## üéØ Next Steps

1. ‚úÖ **Bronze Layer** - Raw data ingestion (completed)
2. üîÑ **Silver Layer** - Data cleaning & transformation
3. üîÑ **Gold Layer** - Business aggregations
4. üîÑ **Monitoring** - Grafana dashboards
5. üîÑ **Airflow** - Orchestration & scheduling

---

**üìù Last Updated:** November 25, 2025  
**üîñ Version:** 1.2.0


