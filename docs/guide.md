# HÆ°á»›ng dáº«n Video Analytics Pipeline (Ingest â†’ YOLOv8 â†’ DeepSORT â†’ Export)

Video pipeline thá»±c hiá»‡n luá»“ng xá»­ lÃ½ video hoÃ n chá»‰nh: **Ingest video** â†’ **Object Detection** â†’ **Object Tracking** â†’ **Export Metadata**

## ğŸ¯ Tá»•ng quan Pipeline

**Pipeline Components:**
- **Ingest**: Äá»c video tá»« file MP4/RTSP qua GStreamer hoáº·c OpenCV
- **Detect**: PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng (ngÆ°á»i, xe, Ä‘á»“ váº­t) báº±ng YOLOv8 
- **Track**: Theo dÃµi Ä‘á»‘i tÆ°á»£ng qua cÃ¡c frame báº±ng DeepSORT
- **Emit**: Xuáº¥t metadata detection/tracking dáº¡ng NDJSON

**Luá»“ng xá»­ lÃ½**: `Video Frame` â†’ `YOLO Detection` â†’ `DeepSORT Tracking` â†’ `JSON Metadata` â†’ `Display/Export`

## ğŸ“ Cáº¥u trÃºc chi tiáº¿t thÆ° má»¥c /ai

```
ai/
â”œâ”€â”€ ingest/                   # Module Ä‘á»c vÃ  Ä‘iá»u phá»‘i video
â”‚   â”œâ”€â”€ __init__.py          # Package init (4 dÃ²ng)
â”‚   â”œâ”€â”€ __main__.py          # â­ CLI chÃ­nh Ä‘iá»u phá»‘i pipeline (160 dÃ²ng)
â”‚   â”œâ”€â”€ gst_source.py        # GStreamer video backend (90 dÃ²ng)
â”‚   â””â”€â”€ cv_source.py         # OpenCV video backend (32 dÃ²ng)
â”œâ”€â”€ detect/                  # Module object detection
â”‚   â””â”€â”€ yolo_detector.py     # â­ YOLOv8 wrapper (33 dÃ²ng)
â”œâ”€â”€ track/                   # Module object tracking  
â”‚   â””â”€â”€ deepsort_tracker.py  # â­ DeepSORT wrapper (80 dÃ²ng)
â””â”€â”€ emit/                    # Module xuáº¥t káº¿t quáº£
    â””â”€â”€ json_emitter.py      # â­ NDJSON metadata exporter (90 dÃ²ng)
```
## ğŸ”§ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

**Python 3.12** (khuyáº¿n nghá»‹ trÃªn Windows)

1) Táº¡o virtual environment (venv)

```bash
py -3.12 -m venv .venv312
```

2) KÃ­ch hoáº¡t venv â€” chá»n lá»‡nh phÃ¹ há»£p vá»›i shell báº¡n Ä‘ang dÃ¹ng:

- cmd.exe (Command Prompt):

```powershell
.venv312\Scripts\activate.bat
```

- PowerShell:

```powershell
.venv312\Scripts\Activate.ps1
```

- Git Bash / WSL / bash.exe:

```bash
source .venv312/Scripts/activate
```

LÆ°u Ã½: náº¿u báº¡n khÃ´ng muá»‘n/khÃ´ng thá»ƒ kÃ­ch hoáº¡t venv, cÃ³ thá»ƒ cháº¡y pip thÃ´ng qua Python cá»¥ thá»ƒ:`py -3.12 -m pip ...`.

3) CÃ i dependencies (cháº¡y sau khi Ä‘Ã£ activate hoáº·c dÃ¹ng `py -3.12 -m pip`)

```bash
# (sau khi Ä‘Ã£ activate) 
py -3.12 -m pip install --upgrade pip wheel setuptools
py -3.12 -m pip install ultralytics opencv-python deep-sort-realtime
```

4) Kiá»ƒm tra cÃ i Ä‘áº·t (tÃ¹y shell)

- TrÃªn bash (Git Bash / WSL):

```bash
py -3.12 -m pip list | grep -E "(ultralytics|opencv|deep-sort)"
```

- TrÃªn Windows cmd / PowerShell (dÃ¹ng findstr thay cho grep):

```powershell
py -3.12 -m pip list | findstr /R "ultralytics opencv deep-sort"
```

## ğŸš€ CÃ¡ch cháº¡y Pipeline tá»«ng bÆ°á»›c

### BÆ°á»›c 1: Chuáº©n bá»‹ video test

```bash
# Táº¡o video tá»•ng há»£p Ä‘á»ƒ test (náº¿u chÆ°a cÃ³ video thá»±c)
py -3.12 scripts/make_synth_video.py
# â†’ Táº¡o data/synth.avi

# Hoáº·c dÃ¹ng video thá»±c cÃ³ sáºµn
ls "data/videos/"
```

### BÆ°á»›c 2: Cháº¡y Pipeline cÆ¡ báº£n (vá»›i display)

```bash
# Test vá»›i video thá»±c - hiá»ƒn thá»‹ cá»­a sá»• preview
py -3.12 -m ai.ingest \
  --backend cv \
  --src "data/videos/Midtown corner store surveillance video 11-25-18.mp4" \
  --yolo 1 \
  --track 1 \
  --display 1
```

**Ã nghÄ©a tá»«ng tham sá»‘:**
- `--backend cv`: DÃ¹ng OpenCV Ä‘á»ƒ Ä‘á»c video (á»•n Ä‘á»‹nh, khÃ´ng cáº§n GStreamer)
- `--src`: ÄÆ°á»ng dáº«n file video input  
- `--yolo 1`: Báº­t YOLO detection (phÃ¡t hiá»‡n ngÆ°á»i, xe, Ä‘á»“ váº­t)
- `--track 1`: Báº­t DeepSORT tracking (gÃ¡n ID cho Ä‘á»‘i tÆ°á»£ng qua frames)
- `--display 1`: **Hiá»ƒn thá»‹ cá»­a sá»• preview** Ä‘á»ƒ xem trá»±c quan quÃ¡ trÃ¬nh detect/track

### BÆ°á»›c 3: Cháº¡y Pipeline vá»›i xuáº¥t NDJSON

```bash
# Cháº¡y Ä‘áº§y Ä‘á»§ + export metadata
py -3.12 -m ai.ingest \
  --backend cv \
  --src "data/videos/Midtown corner store surveillance video 11-25-18.mp4" \
  --yolo 1 \
  --track 1 \
  --display 1 \
  --emit detection \
  --out detections_output.ndjson
```

```bash
py -3.12 -m ai.ingest \
  --backend cv \
  --src "data/videos/video.mp4" \
  --yolo 1 \
  --track 1 \
  --display 1 \
  --emit detection \
  --out detections_output.ndjson
```

<<<<<<< HEAD
```bash
py -3.12 -m ai.ingest \
  --backend cv \
  --src "data/videos/video.mp4" \
  --yolo 1 \
  --track 1 \
  --display 1 \
  --emit detection \
  --out detections_midtown_t3.ndjson \
  --conf 0.25 \
  --track_max_age 90 \
  --track_n_init 3 \
  --track_iou 0.8 \
  --track_nms_overlap 0.9
```

Náº¿u cÃ³ GPU, cÃ³ thá»ƒ báº­t embedder GPU Ä‘á»ƒ tÄƒng re-identification: `--track_embedder_gpu 1`

### BÆ°á»›c 4: Kiá»ƒm tra káº¿t quáº£

```bash
# Xem thÃ´ng tin file output
ls -la detections_output.ndjson
wc -l detections_output.ndjson

# Xem sample output
head -2 detections_output.ndjson | jq .
```

## ğŸ“Š Äá»c hiá»ƒu Log Output

```
[INFO] Frames=30 | Res=1280x720 | ~9.8 FPS | det_total=33 | active_tracks=0
```

**Giáº£i thÃ­ch:**
- `Frames=30`: ÄÃ£ xá»­ lÃ½ 30 frames
- `Res=1280x720`: Resolution video 
- `~9.8 FPS`: Tá»‘c Ä‘á»™ xá»­ lÃ½ pipeline
- `det_total=33`: Tá»•ng sá»‘ detection tá»« Ä‘áº§u
- `active_tracks=0`: Sá»‘ Ä‘á»‘i tÆ°á»£ng Ä‘ang Ä‘Æ°á»£c track

## ğŸ›ï¸ Tuá»³ chá»‰nh Pipeline

### Chá»‰ Detection (khÃ´ng Tracking)
```bash
py -3.12 -m ai.ingest --backend cv --src video.mp4 --yolo 1 --track 0 --display 1
```

### Thay Ä‘á»•i model YOLO
```bash
py -3.12 -m ai.ingest --backend cv --src video.mp4 --model yolov8s.pt --conf 0.5 --display 1
```

### Lá»c chá»‰ detect ngÆ°á»i
```bash
py -3.12 -m ai.ingest --backend cv --src video.mp4 --classes person --display 1
```

### Äiá»u chá»‰nh metadata nguá»“n
```bash
py -3.12 -m ai.ingest \
  --src video.mp4 \
  --store_id "store_downtown" \
  --camera_id "cam_entrance" \
  --stream_id "main_feed" \
  --display 1
```

## ğŸ” GStreamer Backend (Advanced)

**Khi nÃ o dÃ¹ng GStreamer:**
- Xá»­ lÃ½ RTSP streams tá»« IP cameras
- Cáº§n hiá»‡u nÄƒng tá»‘t vá»›i H.264 decoding
- Xá»­ lÃ½ nhiá»u stream Ä‘á»“ng thá»i

```bash
# Thá»­ GStreamer (sáº½ fallback OpenCV náº¿u thiáº¿u 'gi')
py -3.12 -m ai.ingest --backend gst --src video.mp4 --display 1

# RTSP stream (khi cÃ³ GStreamer)
py -3.12 -m ai.ingest --backend gst --src "rtsp://user:pass@192.168.1.100/stream" --display 1
```

## ğŸ“„ Format NDJSON Output

Má»—i dÃ²ng lÃ  JSON cá»§a 1 frame:

```json
{
  "schema_version": "1.0",
  "pipeline_run_id": "unique-run-id", 
  "source": {
    "store_id": "store_01",
    "camera_id": "cam_01", 
    "stream_id": "stream_01"
  },
  "frame_index": 1,
  "capture_ts": "2025-09-02T03:00:13.891188+00:00",
  "detections": [
    {
      "det_id": "1-0",
      "class": "person",
      "class_id": 0, 
      "conf": 0.823,
      "bbox": {"x1": 344, "y1": 58, "x2": 438, "y2": 430},
      "bbox_norm": {"x": 0.269, "y": 0.081, "w": 0.073, "h": 0.517},
      "centroid": {"x": 391, "y": 244},
      "track_id": null
    }
  ]
}
```

## âš ï¸ Troubleshooting

### Lá»—i thiáº¿u dependencies
```bash
# Kiá»ƒm tra packages
py -3.12 -m pip list | grep -E "(ultralytics|opencv|deep-sort)"

# CÃ i láº¡i náº¿u thiáº¿u
py -3.12 -m pip install ultralytics opencv-python deep-sort-realtime
```

### Video khÃ´ng load Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra file tá»“n táº¡i
ls -la "data/videos/"

# Test vá»›i video Ä‘Æ¡n giáº£n
py -3.12 scripts/make_synth_video.py
py -3.12 -m ai.ingest --backend cv --src data/synth.avi --display 1
```

### GStreamer fallback
```
[WARN] GStreamer backend khÃ´ng sáºµn sÃ ng (thiáº¿u gi). Tá»± Ä‘á»™ng chuyá»ƒn sang OpenCV.
```
**â†’ BÃ¬nh thÆ°á»ng**, pipeline váº«n hoáº¡t Ä‘á»™ng vá»›i OpenCV backend.

### KhÃ´ng tháº¥y detection
- Video tá»•ng há»£p (`synth.avi`) cÃ³ thá»ƒ khÃ´ng cÃ³ Ä‘á»‘i tÆ°á»£ng thá»±c â†’ bÃ¬nh thÆ°á»ng
- DÃ¹ng video surveillance cÃ³ ngÆ°á»i/xe Ä‘á»ƒ tháº¥y detection
- Giáº£m `--conf` (máº·c Ä‘á»‹nh 0.25) Ä‘á»ƒ detection nháº¡y hÆ¡n

## ğŸ¯ Use Cases thá»±c táº¿

**Retail Surveillance:**
```bash
py -3.12 -m ai.ingest \
  --src "rtsp://camera-ip/stream" \
  --classes "person,bag,bottle" \
  --store_id "walmart_downtown" \
  --camera_id "checkout_cam_03" \
  --emit detection \
  --out retail_detections.ndjson \
  --display 1
```

**Traffic Monitoring:**
```bash  
py -3.12 -m ai.ingest \
  --src traffic_video.mp4 \
  --classes "car,truck,bus,motorcycle" \
  --track 1 \
  --emit detection \
  --out traffic_analysis.ndjson \
  --display 1
```

## ğŸ› ï¸ Khá»Ÿi Ä‘á»™ng háº¡ táº§ng Pulsar & Flink

```bash
# Báº­t Pulsar (broker + script init schema/topic)
docker compose up -d pulsar-broker pulsar-init

# Báº­t Flink JobManager + TaskManager
docker compose up -d flink-jobmanager flink-taskmanager

# Kiá»ƒm tra nhanh
docker compose ps
curl http://localhost:8081/overview
docker compose logs pulsar-init | tail
```

**LÆ°u Ã½:**
- `pulsar-init` chá»‰ cháº¡y má»™t láº§n Ä‘á»ƒ táº¡o tenant/topic, cÃ³ thá»ƒ xoÃ¡ container sau khi hoÃ n táº¥t.
- Muá»‘n khá»Ÿi cháº¡y láº¡i init, dÃ¹ng `docker compose run --rm pulsar-init`.
- CÃ¡c volume `pulsar_data` vÃ  `flink_state` giá»¯ tráº¡ng thÃ¡i giá»¯a cÃ¡c láº§n restart.

---

**ğŸ’¡ Tip**: LuÃ´n dÃ¹ng `--display 1` khi test Ä‘á»ƒ theo dÃµi trá»±c quan pipeline hoáº¡t Ä‘á»™ng!

## CÃ¡c tham sá»‘ nÃ¢ng cao DeepSORT

- `--track_max_age INT` (ENV: `TRACK_MAX_AGE`): sá»‘ frame giá»¯ track khi máº¥t (máº·c Ä‘á»‹nh 30)
- `--track_n_init INT` (ENV: `TRACK_N_INIT`): sá»‘ láº§n hit Ä‘á»ƒ xÃ¡c nháº­n track (máº·c Ä‘á»‹nh 3)
- `--track_iou FLOAT` (ENV: `TRACK_IOU`): ngÆ°á»¡ng IoU cho matching (máº·c Ä‘á»‹nh 0.7)
- `--track_nms_overlap FLOAT` (ENV: `TRACK_NMS_OVERLAP`): NMS overlap (1.0 = táº¯t NMS)
- `--track_embedder STR` (ENV: `TRACK_EMBEDDER`): embedder appearance (`mobilenet`, v.v.)
- `--track_embedder_gpu {0|1}` (ENV: `TRACK_EMBEDDER_GPU`): báº­t GPU cho embedder
- `--track_half {0|1}` (ENV: `TRACK_EMBEDDER_HALF`): dÃ¹ng FP16 cho mobilenet embedder

## CÃ¡c tham sá»‘ CLI cÆ¡ báº£n

- `--src`: Ä‘Æ°á»ng dáº«n file hoáº·c RTSP URL (báº¯t buá»™c)
- `--backend {gst,cv}`: chá»n backend ingest (máº·c Ä‘á»‹nh: `gst`, tá»± fallback `cv` náº¿u thiáº¿u `gi`)
- `--yolo {0|1}`: báº­t/táº¯t YOLO detect (máº·c Ä‘á»‹nh 1)
- `--track {0|1}`: báº­t/táº¯t DeepSORT tracking (máº·c Ä‘á»‹nh 1)
- `--display {0|1}`: hiá»ƒn thá»‹ preview báº±ng OpenCV (máº·c Ä‘á»‹nh 1)
- `--fps_log N`: chu ká»³ log FPS (máº·c Ä‘á»‹nh 30)
- `--emit {none|detection}` + `--out PATH`: xuáº¥t NDJSON theo frame
- Metadata nguá»“n: `--store_id`, `--camera_id`, `--stream_id`, `--run_id`

## Äá»‹nh dáº¡ng NDJSON chi tiáº¿t

Má»—i dÃ²ng lÃ  má»™t JSON vá»›i cÃ¡c trÆ°á»ng: `schema_version`, `pipeline_run_id`, `source{store_id,camera_id,stream_id}`, `frame_index`, `capture_ts`, `detections[]`.

Má»—i detection: `class`, `class_id`, `conf`, `bbox{x1,y1,x2,y2}`, `bbox_norm{x,y,w,h}`, `centroid{x,y}`, `track_id|null`.

## Hiá»‡u nÄƒng & GPU

- YOLOv8 cÃ³ thá»ƒ dÃ¹ng GPU náº¿u PyTorch/CUDA sáºµn sÃ ng; máº·c Ä‘á»‹nh cháº¡y CPU Ä‘á»ƒ Ä‘Æ¡n giáº£n.
- DeepSORT embedder máº·c Ä‘á»‹nh 'mobilenet', cháº¡y CPU (chÃºng tÃ´i báº­t `embedder_gpu=False`).

## Kháº¯c phá»¥c sá»± cá»‘ nhanh

- Lá»—i import `ultralytics/opencv-python/deep_sort_realtime`: kiá»ƒm tra Ä‘Ã£ cÃ i Ä‘Ãºng Python phiÃªn báº£n Ä‘ang cháº¡y (`py -3.12 -m pip list`).
- Lá»—i `gi` khÃ´ng cÃ³: backend GStreamer sáº½ fallback sang OpenCV; náº¿u muá»‘n dÃ¹ng GStreamer, xem má»¥c GStreamer Backend.
- KhÃ´ng tháº¥y detection trÃªn video máº«u: bÃ¬nh thÆ°á»ng. HÃ£y cháº¡y vá»›i video thá»±c táº¿ cÃ³ ngÆ°á»i/váº­t.
- RTSP lag: thá»­ GStreamer backend (`--backend gst`) sáº½ á»•n Ä‘á»‹nh hÆ¡n OpenCV cho H.264/RTSP.
=======
>>>>>>> main
